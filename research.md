---
title: Dependable, Efficient, and Intelligent Computing Lab (DETAIL)
---
## [Home](./) | [People](./people) | [**Research**](./research) | [Publication](./publication) | [About](./about) | [Artifact](./artifact) 

## Robust/Dependable AI 
Recent development in artificial intelligence (AI) and machine learning (ML), e.g., deep neural networks (DNNs), promise enormous societal and economic benefits. However, the robustness/dependability of AI/ML systems face severe challenges stemming from uncertain or adversarial conditions, such as hardware failures, software errors, security threats, or environmental disruptions. For example, Google and Meta have both reported notable instances of hardware errors occurring in their data centers, causing substantial impact on the service. To tackle this problem, we have developed cross-layer solutions spanning hardware and algorithm layers. 

* Robust AI Against Unreliable Hardware: We have tested and enhanced AI/ML robustness against hardware errors, e.g., bit flips in computation and/or in memory. [ICCAD’17, D&T’20, ICCAD’22, DATE’22]. 
* Robust AI Against Adversarial Data: We have tested and enhanced AI robustness against uncertain/adversarial input, e.g., carefully-crafted images with invisible perturbation. [DAC’21, DATE’22, DATE’23, TCAD’23]. 

## Brain-Inspired Hyperdimensional Computing
Hyperdimensional computing (HDC), also known as vector symbolic architectures (VSA), was introduced as an alternative computational model mimicking the “human brain” at
the functionality level. Compared with deep neural networks, the advantages of HDC include smaller model size, less computation cost, and one/few-shot learning, making it a promising alternative computing paradigm. We explore this novel learning approach in multiple aspects:

* We develop HDC models for various application domains, such as NLP, sensor attack detection, and drug discovery. [DAC'22, ISVLSI'21, RTAS'21, BIBM'22, DATE'23]
* We develop energy-efficient and robust solutions for HDC systems. [ICCAD'22, DATE'22, DAC'21, ASAP'21, ISVLSI'21, TCAD'23] 


## Energy-Efficient Computing 
Energy efficiency has become a top priority for both high-performance computing systems (e.g., data center) and resource-constrained embedded systems (e.g., mobile/IoT device). The design of energy-efficient computing systems often needs to consider the tradeoff between performance, robustness/reliability, and efficiency. We adopt a cross-layer approach to tackle this problem.  

*	We are the first to develop input-aware circuit error model under dynamic voltage and frequency scaling (DVFS), a most-widely used energy-efficiency technique used in computing. This machine learning-based model can provide accurate understanding and guidance for energy-efficient design. [ICCD'16, DATE'17, TC'18, DAC'20, TCAD'21, TCAD'22]  
*	We propose novel approximate computing solutions (e.g., approximate circuits, in-memory computing, voltage scaling) in circuit, architecture, and application layers to enable energy-efficient processing of emerging workloads such as AI and multimedia. [TC'18, DATE'18, GLSVLSI'20, DSD'20 (Oustanding Paper Award), DATE'22 (Best Paper Candidate), ICCAD'22]
