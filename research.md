---
title: Dependable, Efficient, and Intelligent Computing Lab (DETAIL)
---
## [Home](./) | [People](./people) | [**Research**](./research) | [Publication](./publication) | [About](./about) | [Artifact](./artifact) 

## Robust/Dependable AI 
Recent development in artificial intelligence (AI) and machine learning (ML), e.g., deep neural networks (DNNs), promise enormous societal and economic benefits. However, the robustness/dependability of AI/ML systems face severe challenges stemming from uncertain or adversarial conditions, such as hardware failures, software errors, security threats, or environmental disruptions. For example, Google and Meta have both reported notable instances of hardware errors occurring in their data centers, causing substantial impact on the service. To tackle this problem, we have developed cross-layer solutions spanning hardware and algorithm layers. 

* Robust AI Against Unreliable Hardware: We have tested and enhanced AI/ML robustness against hardware errors, e.g., bit flips in computation and/or in memory. [ICCAD’17, D&T’20, ICCAD’22, DATE’22]. 
* Robust AI Against Adversarial Data: We have tested and enhanced AI robustness against uncertain/adversarial input, e.g., carefully-crafted images with invisible perturbation. [DAC’21, DATE’22, DATE’23, TCAD’23].

## Approximate Computing 
As Moore’s Law slows down and transistor scaling is increasingly less effective in improving performance and energy efficiency, alternative computing paradigms are urgently needed as we look to the future of the computing industry. Approximate computing has recently arisen as a promising candidate for resolving this challenge due to its success in many modern applications such as deep learning, image/vision processing, and data mining/search. We have developed cross-layer approximate computing solutions spanning hardware, architecture, to software and algorithms.    

*	We developed inexact logic circuits [DATE'17], and circuit-level error model for approximate circuits under voltage scaling. [ICCD'16, DATE'17, TC'18, DAC'20, TCAD'21, TCAD'22]  
*	We developed cross-layer approximate computing design to support deep learning and multimedia applications. [DATE'18, GLSVLSI'20, TNNLS'22]
*	

## Brain-Inspired Hyperdimensional Computing
Hyperdimensional computing (HDC), also known as vector symbolic architectures (VSA), was introduced as an alternative computational model mimicking the “human brain” at
the functionality level. Compared with deep neural networks, the advantages of HDC include smaller model size, less computation cost, and one/few-shot learning, making it a promising alternative computing paradigm. We explore this novel learning approach in multiple aspects:

* We develop HDC models for various application domains, such as NLP, sensor attack detection, and drug discovery. [DAC'22, ISVLSI'21, RTAS'21, BIBM'22, DATE'23]
* We develop energy-efficient and robust HDC systems. [ICCAD'22, DATE'22, DAC'21, ASAP'21, ISVLSI'21, TCAD'23] 
